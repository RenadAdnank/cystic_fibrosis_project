# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZvFB-6b-Z8MnXiqFCUa_PnRLt4XhKrf
"""

from google.colab import files
uploaded = files.upload()

import os
import zipfile

# إنشاء مجلد مخفي .kaggle
os.makedirs("/root/.kaggle", exist_ok=True)

# نقل ملف kaggle.json إليه
with open("/root/.kaggle/kaggle.json", "w") as f:
    # The following lines need to be indented to be part of the 'with' block
    filename = list(uploaded.keys())[0]
    f.write(uploaded[filename].decode())
# تعيين صلاحيات الملف
os.chmod("/root/.kaggle/kaggle.json", 600)

!kaggle datasets download -d ukveteran/cystic-fibrosis-data

with zipfile.ZipFile("cystic-fibrosis-data.zip", 'r') as zip_ref:
    zip_ref.extractall("cf_data")

files = os.listdir("cf_data")
files

import pandas as pd
df = pd.read_csv("cf_data/cf.csv")
df.head()

if 'Unnamed: 0' in df.columns:
    df = df.drop(columns=["Unnamed: 0"])
else:
    print("Column 'Unnamed: 0' not found in DataFrame.")

num_attributes = df.shape[1] - 1
print("Number of attributes:", num_attributes)

print("Number of samples:",df.shape[0])

df.describe()

df.isnull().sum().sum()

import matplotlib.pyplot as plt

df.hist(figsize=(15, 12), bins=3)
plt.tight_layout()
plt.show()

import seaborn as sns

sns.countplot(data=df, x='y')
plt.title("Target Class Distribution")
plt.show()

import numpy as np

plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=False, cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of All Features")
plt.xticks(rotation=90)
plt.show()

from sklearn.preprocessing import StandardScaler
X = df.drop(columns=['y'])
y = df['y']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pd.DataFrame(X_scaled, columns=X.columns).head()

import pandas as pd
from sklearn.model_selection import train_test_split

# Load the data
data = pd.read_csv('cf_data/cf.csv')

# Split the data into features (X) and target (y)
X = data.drop('y', axis=1)  # Features
y = data['y']  # Target values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Save the split data into CSV files
X_train.to_csv('X_train.csv', index=False)
X_test.to_csv('X_test.csv', index=False)
y_train.to_csv('y_train.csv', index=False)
y_test.to_csv('y_test.csv', index=False)

print("Data has been successfully split and saved.")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


# Replace 'target_column_name' with 'y' which is the actual name of the target column
X = df.drop(columns=['y'])
y = df['y']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


models = {
    "Logistic Regression": LogisticRegression(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Support Vector Machine": SVC(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier()
}


results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    acc = accuracy_score(y_test, predictions)
    results[name] = acc
    print(f"{name}: Accuracy = {acc:.2f}")

best_model = max(results, key=results.get)
worst_model = min(results, key=results.get)

print(f"\nBest Performing Model: {best_model} with accuracy {results[best_model]:.2f}")
print(f"Worst Performing Model: {worst_model} with accuracy {results[worst_model]:.2f}")

# استيراد المكتبات

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# 1. تحميل البيانات
def load_data():
    # Update the path to your actual data file
    original_data = pd.read_csv('cf_data/cf.csv')  # Changed path here to 'cf_data/cf.csv'
    return original_data

# 2. معالجة البيانات
def preprocess_data(data):
    processed_data = data.dropna()
    return processed_data

# 3. بناء النموذج
def build_model():
    model = RandomForestClassifier()
    return model

# 4. تدريب النموذج
def train_model(model, X_train, y_train):
    model.fit(X_train, y_train)
    return model

# 5. تقييم النموذج
def evaluate_model(model, X_test, y_test):
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    return accuracy

# 6. الحصول على التوقعات
def get_predictions(model, X):
    predictions = model.predict(X)
    return predictions

# 7. حفظ النتائج
def save_predictions(predictions, filename):
    pd.DataFrame(predictions).to_csv(filename, index=False)

# 8. تنفيذ جميع الخطوات
def main():
    data = load_data()
    processed_data = preprocess_data(data)

    # Assuming 'y' is your target column, update if different
    X = processed_data.drop('y', axis=1)  # Changed 'target' to 'y'
    y = processed_data['y']           # Changed 'target' to 'y'

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = build_model()
    trained_model = train_model(model, X_train, y_train)

    accuracy = evaluate_model(trained_model, X_test, y_test)
    print(f"Model accuracy: {accuracy}")

    predictions = get_predictions(trained_model, X_test)
    save_predictions(predictions, 'predictions_RF_model.csv')

# تشغيل البرنامج
main()

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
import os
import pandas as pd

# 1. إنشاء النموذج
nb_model = GaussianNB()

# 2. تدريب النموذج
nb_model.fit(X_train, y_train)

# 3. التنبؤ على بيانات الاختبار
nb_predictions = nb_model.predict(X_test)

# 4. تقييم الدقة
nb_accuracy = accuracy_score(y_test, nb_predictions)
print(f"Naive Bayes Accuracy: {nb_accuracy:.2f}")

# 5. التأكد من وجود مجلد النتائج
os.makedirs("data/Results", exist_ok=True)

# 6. حفظ التوقعات في ملف CSV
pd.DataFrame(nb_predictions).to_csv("data/Results/predictions_NB_model.csv", index=False)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, accuracy_score
import numpy as np
import os
import pandas as pd

# 1. إنشاء النموذج
lr_model = LinearRegression()

# 2. تدريب النموذج
lr_model.fit(X_train, y_train)

# 3. التنبؤ
lr_predictions_raw = lr_model.predict(X_test)

# 4. تحويل التوقعات إلى فئات (0 أو 1) لأن المشكلة تصنيف
lr_predictions = np.round(lr_predictions_raw).astype(int)

# 5. تقييم الأداء بدقة التصنيف
lr_accuracy = accuracy_score(y_test, lr_predictions)
print(f"Linear Regression Accuracy (rounded to class): {lr_accuracy:.2f}")

# 6. إنشاء مجلد النتائج إن لم يكن موجودًا
os.makedirs("data/Results", exist_ok=True)

# 7. حفظ التوقعات
pd.DataFrame(lr_predictions).to_csv("data/Results/predictions_LR_model.csv", index=False)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# تقسيم البيانات
X = df.drop(columns=['y'])
y = df['y']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# المقياس (Standardization)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.neural_network import MLPClassifier

# 1. إنشاء النموذج
ann_model = MLPClassifier(max_iter=1000, random_state=42)

# 2. تدريب النموذج
ann_model.fit(X_train,y_train)

# 3. التنبؤ
ann_predictions = ann_model.predict(X_test)

# 4. حساب الدقة
ann_accuracy = accuracy_score(y_test, ann_predictions)
print(f"ANN Accuracy: {ann_accuracy:.2f}")

# 5. حفظ التوقعات
os.makedirs("data/Results", exist_ok=True)
pd.DataFrame(ann_predictions).to_csv("data/Results/predictions_ANN_model.csv", index=False)

# 6. إضافة إلى الرسم البياني
results["Artificial Neural Network"] = ann_accuracy

results["Naive Bayes"] = nb_accuracy
results["Artificial Neural Network"] = ann_accuracy
results["Linear Regression"] = lr_accuracy

results_df = pd.DataFrame(list(results.items()), columns=["Model", "Accuracy"])

results["Naive Bayes"] = nb_accuracy
results["Artificial Neural Network"] = ann_accuracy
results["Linear Regression"] = lr_accuracy

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.bar(results_df['Model'], results_df['Accuracy'], color='skyblue')
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

results_df = pd.DataFrame(list(results.items()), columns=["Model", "Accuracy"])
print(results_df)

results_df = pd.DataFrame(list(results.items()), columns=["Model", "Accuracy"])

plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")

barplot = sns.barplot(x="Accuracy", y="Model", data=results_df, palette="viridis", edgecolor=".2")

for container in barplot.containers:
    barplot.bar_label(container, fmt='%.2f', label_type='edge', padding=3)

plt.title("Comparison of Model Accuracies", fontsize=16)
plt.xlabel("Accuracy")
plt.ylabel("Model")
plt.xlim(0, 1)
plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# مثال: نطبقه على نموذج Linear Regression بعد تقريب التوقعات
# تأكدي أن y_test و lr_predictions موجودين مسبقًا

print("Classification Report:\n", classification_report(y_test, lr_predictions))

# إنشاء مصفوفة الالتباس
cm = confusion_matrix(y_test, lr_predictions)

# رسم المصفوفة
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greys")
plt.title("Confusion Matrix - Linear Regression")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
svm_model = SVC()
svm_model.fit(X_train, y_train)

# Get predictions for SVM
predictions_svm = svm_model.predict(X_test)
# عرض تقرير الأداء
# Changed y_pred_svm to predictions_svm
print("Classification Report for SVM:\n", classification_report(y_test, predictions_svm))

# مصفوفة الالتباس
# Changed y_pred_svm to predictions_svm
cm = confusion_matrix(y_test, predictions_svm)

# الرسم
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - SVM")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# Load your data (replace with your actual data loading)
data = pd.read_csv('cf_data/cf.csv')  # Assuming your data is in 'cf_data/cf.csv'
X = data.drop('y', axis=1)
y = data['y']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Create and train the SVM model
svm_model = SVC()
svm_model.fit(X_train, y_train)

# Get predictions
predictions_svm = svm_model.predict(X_test) # predictions_svm is assigned here

# Save predictions
import os
os.makedirs("Results", exist_ok=True)
pd.DataFrame(predictions_svm, columns=["Prediction"]).to_csv("Results/predictions_SVM_model.csv", index=False)

import pandas as pd

df = pd.read_csv("cf_data/cf.csv")
print(df.head())

from sklearn.model_selection import train_test_split
import os

# فصل السمات والهدف
X = df.drop(columns=['y'])
y = df['y']

# تقسيم البيانات
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# إنشاء المجلد المطلوب
os.makedirs("data/preprocessed_data", exist_ok=True)

# حفظ الملفات داخل المجلد
X_train.to_csv("data/preprocessed_data/X.csv", index=False)
X_test.to_csv("data/preprocessed_data/X_test.csv", index=False)
y_train.to_csv("data/preprocessed_data/Y.csv", index=False)
y_test.to_csv("data/preprocessed_data/Y_test.csv", index=False)

print("تم حفظ الملفات في data/preprocessed_data/")

from sklearn.neighbors import KNeighborsClassifier

# إعادة تدريب النموذج (إذا لم يكن مدرب مسبقًا)
knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)

# التنبؤ
knn_predictions = knn_model.predict(X_test)

# التأكد من وجود مجلد النتائج
os.makedirs("data/Results", exist_ok=True)

# حفظ التوقعات
pd.DataFrame(knn_predictions, columns=["Prediction"]).to_csv("data/Results/predictions_KNN_model.csv", index=False)

import os
os.makedirs("data/original data", exist_ok=True)

# نسخ الملف من مجلد cf_data إلى المسار الصحيح
!cp cf_data/cf.csv "data/original data/cf.csv"

import os
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

# التأكد من وجود مجلد النتائج
os.makedirs("data/Results", exist_ok=True)

# 1. Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
rf_predictions = rf_model.predict(X_test)
pd.DataFrame(rf_predictions, columns=["Prediction"]).to_csv("data/Results/predictions_RF_model.csv", index=False)
print("Saved predictions_RF_model.csv")

# 2. Support Vector Machine
svm_model = SVC(random_state=42)
svm_model.fit(X_train, y_train)
svm_predictions = svm_model.predict(X_test)
pd.DataFrame(svm_predictions, columns=["Prediction"]).to_csv("data/Results/predictions_SVM_model.csv", index=False)
print("Saved predictions_SVM_model.csv")

# 3. ANN (MLPClassifier)
ann_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
ann_model.fit(X_train, y_train)
ann_predictions = ann_model.predict(X_test)
pd.DataFrame(ann_predictions, columns=["Prediction"]).to_csv("data/Results/predictions_ANN_model.csv", index=False)
print("Saved predictions_ANN_model.csv")
